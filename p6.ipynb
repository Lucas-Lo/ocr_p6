{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 6\n",
    "## Description du projet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\C0002630\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\C0002630\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# New packages\n",
    "\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import sys, os\n",
    "import skimage.io as io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from nltk.corpus import stopwords ; nltk.download('stopwords') ; nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "path_to_csv = os.path.join(\"data\", \"flipkart_com-ecommerce_sample_1050.csv\")\n",
    "path_to_images_folder = os.path.join(\"data\", \"images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   uniq_id                  1050 non-null   object \n",
      " 1   crawl_timestamp          1050 non-null   object \n",
      " 2   product_url              1050 non-null   object \n",
      " 3   product_name             1050 non-null   object \n",
      " 4   product_category_tree    1050 non-null   object \n",
      " 5   pid                      1050 non-null   object \n",
      " 6   retail_price             1049 non-null   float64\n",
      " 7   discounted_price         1049 non-null   float64\n",
      " 8   image                    1050 non-null   object \n",
      " 9   is_FK_Advantage_product  1050 non-null   bool   \n",
      " 10  description              1050 non-null   object \n",
      " 11  product_rating           1050 non-null   object \n",
      " 12  overall_rating           1050 non-null   object \n",
      " 13  brand                    712 non-null    object \n",
      " 14  product_specifications   1049 non-null   object \n",
      "dtypes: bool(1), float64(2), object(12)\n",
      "memory usage: 116.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_csv)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(10):\n",
    "#     img_path = os.path.join(\"data\", \"images\", df.loc[idx, \"image\"])\n",
    "#     img = io.imread(img_path)\n",
    "#     print(df.loc[idx, \"product_name\"])\n",
    "#     print(df.loc[idx, \"product_category_tree\"])\n",
    "#     # print(df.loc[idx, \"description\"])\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def count_categoriy(category_tree):\n",
    "    # category_tree = category_tree.replace('[\"', '')\n",
    "    # category_tree = category_tree.replace('\"]', '')\n",
    "    category_tree = category_tree.replace('>>', '>')\n",
    "    counter = 1\n",
    "    for elt in category_tree:\n",
    "        if elt == \">\":\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "df[\"nb_of_categories\"] = df[\"product_category_tree\"].apply(count_categoriy)\n",
    "print(df[\"nb_of_categories\"].min())\n",
    "print(df[\"nb_of_categories\"].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 most occurences:\n",
      "of       : 1751\n",
      "for      : 1436\n",
      "the      : 1369\n",
      "and      : 1332\n",
      "to       : 1058\n",
      "in       : 1047\n",
      "rs       : 911\n",
      "only     : 890\n",
      "with     : 843\n",
      "on       : 835\n",
      "a        : 814\n",
      "at       : 714\n",
      "your     : 656\n",
      "is       : 638\n",
      "free     : 618\n",
      "buy      : 581\n",
      "products : 577\n",
      "cm       : 567\n",
      "delivery : 567\n",
      "genuine  : 564\n",
      "==> What is rs? Indian Rupees (money)\n",
      "\n",
      "20 most occurences after removing stopwords:\n",
      "rs       : 911\n",
      "the      : 772\n",
      "free     : 618\n",
      "buy      : 581\n",
      "products : 577\n",
      "cm       : 567\n",
      "delivery : 567\n",
      "genuine  : 564\n",
      "shipping : 564\n",
      "cash     : 564\n",
      "replacement: 559\n",
      "1        : 554\n",
      "day      : 549\n",
      "price    : 541\n",
      "30       : 498\n",
      "flipkart : 481\n",
      "com      : 473\n",
      "guarantee: 471\n",
      "mug      : 406\n",
      "online   : 396\n"
     ]
    }
   ],
   "source": [
    "# Tokenized corpus\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "tokenized_corpus = [tokenizer.tokenize(doc) for doc in df[\"description\"]]\n",
    "\n",
    "# Remove punctuation\n",
    "for text in tokenized_corpus:\n",
    "    for token in text:\n",
    "        if token in string.punctuation:\n",
    "            text.remove(token)\n",
    "\n",
    "# Stemming\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmer = WordNetLemmatizer()\n",
    "# Stem the tokens\n",
    "for i in range(len(tokenized_corpus)):\n",
    "    for j in range(len(tokenized_corpus[i])):\n",
    "        tokenized_corpus[i][j] = stemmer.lemmatize(tokenized_corpus[i][j]).lower()\n",
    "\n",
    "# Count each words\n",
    "bow = [word for text in tokenized_corpus for word in text]\n",
    "bow = Counter(bow)\n",
    "bow = dict(sorted(bow.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"20 most occurences:\")\n",
    "for i in range(20):\n",
    "    word = list(bow.keys())[i]\n",
    "    print(f\"{word:<9}: {bow[word]}\")\n",
    "print(\"==> What is rs? Indian Rupees (money)\\n\")\n",
    "\n",
    "# Drop stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for text in tokenized_corpus:\n",
    "    for word in text:\n",
    "        if word in stop_words:\n",
    "            text.remove(word)\n",
    "\n",
    "# Count each words\n",
    "bow = [word for text in tokenized_corpus for word in text]\n",
    "bow = Counter(bow)\n",
    "bow = dict(sorted(bow.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"20 most occurences after removing stopwords:\")\n",
    "for i in range(20):\n",
    "    word = list(bow.keys())[i]\n",
    "    print(f\"{word:<9}: {bow[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49f5a819dfb3ad0ef33c81c72d060d708f9052ca1509dc70ad6cc32112032782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
